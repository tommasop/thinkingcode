<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
      <title>Techblogs on  </title>
      <generator uri="https://hugo.spf13.com">Hugo</generator>
    <link>http://thinkingco.de/techblog/index.xml/</link>
    
    
    
    <updated>Sat, 04 Jan 2014 02:33:24 &#43;0000</updated>
    
    <item>
      <title>Polymorphic attachments for Rails 4 and ActiveAdmin</title>
      <link>http://thinkingco.de/techblog/polymorphic-attachments-for-rails-4-and-activeadmin/</link>
      <pubDate>Sat, 04 Jan 2014 02:33:24 &#43;0000</pubDate>
      
      <guid>http://thinkingco.de/techblog/polymorphic-attachments-for-rails-4-and-activeadmin/</guid>
      <description>&lt;p&gt;Following my &lt;a href=&#34;http://thinkingco.de/techblog/rails-3-is_documentable-with-activeadmin/&#34;&gt;2012 post!!!&lt;/a&gt; I finally managed to write down a small gem that allows anyone to add multiple files to any model in his rails app.&lt;/p&gt;

&lt;p&gt;The gem has the highly innovative name of: &lt;strong&gt;AttachIt&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;As the original post also took into account ActiveAdmin I managed to add the same functionalities to ActiveAdmin also.&lt;/p&gt;

&lt;p&gt;The gem is thought for use in the show action for your model.&lt;/p&gt;

&lt;p&gt;I have a lot of websites with this requirement of handling multiple files for multiple models so I think this must be a fairly common pattern.&lt;/p&gt;

&lt;p&gt;I also use &lt;a href=&#34;https://github.com/activeadmin/activeadmin&#34;&gt;activeadmin&lt;/a&gt; quite broadly and find it highly flexible. And it is indeed! Here I use &lt;a href=&#34;http://www.dropzonejs.com&#34;&gt;dropzonejs.com&lt;/a&gt; inside activeadmin and also import bootstrap modal and grid to handle the responsive image gallery.&lt;/p&gt;

&lt;p&gt;Enjoy: &lt;a href=&#34;https://github.com/tommasop/attach_it&#34;&gt;https://github.com/tommasop/attach_it&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Migrate Joomla from Windows 2003 to Docker</title>
      <link>http://thinkingco.de/techblog/migrate-joomla-windows-2003-docker/</link>
      <pubDate>Sat, 04 Jan 2014 02:33:24 &#43;0000</pubDate>
      
      <guid>http://thinkingco.de/techblog/migrate-joomla-windows-2003-docker/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Migrate Apache2/PHP website to docker&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Before continuing my series on rails deployment with docker in a PAASY environment I needed to migrate and existing Joomla 1.5 from a Windows 2003 machine to an Azure Ubuntu Linux 12.04.&lt;/p&gt;

&lt;p&gt;Nothing fancy but there is also a Rails application pointing to the same MySql db which also needs to run on the same Linux VM.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;As the Joomla app is the main company website I don’t want any problem in the Rails app to affect the main website.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;With one machine available I decided to follow the &lt;strong&gt;docker&lt;/strong&gt; path.&lt;/p&gt;

&lt;p&gt;Envisioned system is as follows:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Data only container&lt;/li&gt;
&lt;li&gt;MySql container&lt;/li&gt;
&lt;li&gt;Apache2 &amp;#8211; php container&lt;/li&gt;
&lt;li&gt;Rails container&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Data only container&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I started with a base data-only container following the so called &lt;strong&gt;container as volume pattern&lt;/strong&gt;. It is a bare container not even running but existing only to expose common directories to all the other containers. Its data structure is:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;data

&lt;ul&gt;
&lt;li&gt;mysql&lt;/li&gt;
&lt;li&gt;www&lt;/li&gt;
&lt;li&gt;rails&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here is its Dockerfile:&lt;/p&gt;

&lt;pre class=&#34;brush: bash; title: ; notranslate&#34; title=&#34;&#34;&gt;FROM ubuntu:precise
MAINTAINER Thinking Code &amp;lt;a href=&#34;mailto:tommaso@thinkingco.de&#34;&amp;gt;tommaso@thinkingco.de&amp;lt;/a&amp;gt;

# Create data directories

RUN mkdir -p /data/mysql /data/www /data/rails

# Create /data volume

VOLUME [“/data”]

CMD /bin/sh &lt;/pre&gt;

&lt;p&gt;The container can be built and started with the following commands:&lt;/p&gt;

&lt;pre class=&#34;brush: bash; title: ; notranslate&#34; title=&#34;&#34;&gt;docker build -t data-store .
docker run -name my-data-store data-store true &lt;/pre&gt;

&lt;p&gt;If you check the container status you will find it’s exited with code 0 still it can be happily used for data storage. This strange container is the holy grail of data persistence and data migration through containers.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MySql (MariaDB) container&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;As MariaDB is an easy drop in replacement for MySql and is completely open source and i tested with Joomla I opted for this solution. The container will have a single service running exposed on port 3306. Here is the Dockerfile:&lt;/p&gt;

&lt;pre class=&#34;brush: bash; title: ; notranslate&#34; title=&#34;&#34;&gt;# MariaDB (https://mariadb.org/)

FROM ubuntu:precise MAINTAINER Thinking Code &amp;lt;a href=&#34;http://thinkingco.de/&#34;&amp;gt;&amp;lt;&amp;lt;/a&amp;gt;tommaso@thinkingco.de&amp;gt;

# Hack for initctl not being available in Ubuntu

RUN dpkg-divert –local –rename –add /sbin/initctl RUN ln -s /bin/true /sbin/initctl

RUN echo “deb http://archive.ubuntu.com/ubuntu precise main universe” &amp;gt; /etc/apt/sources.list &amp;&amp; \
          apt-get update &amp;&amp; \
          apt-get upgrade -y &amp;&amp; \
          apt-get -y -q install wget logrotate

# Ensure UTF–8

RUN apt-get update
RUN locale-gen en_US.UTF–8
ENV LANG en_US.UTF–8 ENV LC_ALL en_US.UTF–8

# Set noninteractive mode for apt-get

ENV DEBIAN_FRONTEND noninteractive

# Install MariaDB from repository.

RUN apt-get -y install python-software-properties &amp;&amp; \
    apt-key adv –recv-keys –keyserver hkp://keyserver.ubuntu.com:80 0xcbcb082a1bb943db &amp;&amp; \
    add-apt-repository &#39;deb http://mirror.jmu.edu/pub/mariadb/repo/5.5/ubuntu precise main&#39; &amp;&amp; \
    apt-get update &amp;&amp; \
    apt-get install -y mariadb-server

# Decouple our data from our container.

VOLUME [“/data”]

# Configure the database to use our data dir.

RUN sed -i -e &#39;s/^datadir\s&amp;lt;i&amp;gt;=.&amp;lt;/i&amp;gt;/datadir = \/data\/mysql/&#39; /etc/mysql/my.cnf

# Configure MariaDB to listen on any address.

RUN sed -i -e &#39;s/^bind-address/#bind-address/&#39; /etc/mysql/my.cnf

EXPOSE 3306

ADD start.sh /start.sh
RUN chmod +x /start.sh
ENTRYPOINT [“/start.sh”]&lt;/pre&gt;

&lt;p&gt;The &lt;strong&gt;start.sh&lt;/strong&gt; script is the ENTRYPOINT for each container run from the previous Dockerfile image and is responsible for actually starting MariaDB after a setup which includes the setting of a custom datadir, the migration of the existing data in the new directory and the setup of some users and passwords.&lt;/p&gt;

&lt;pre class=&#34;brush: bash; title: ; notranslate&#34; title=&#34;&#34;&gt;&amp;lt;b&amp;gt;!/bin/bash&amp;lt;/b&amp;gt;

# Starts up MariaDB within the container.

# Stop on error

set -e

DATADIR=“/data/mysql”

/etc/init.d/mysql stop

# test if DATADIR has content

if [ ! “$(ls -A $DATADIR)” ]; then
  echo “Initializing MariaDB at $DATADIR” # Copy the data that we generated within the container to the empty DATADIR.
  cp -R /var/lib/mysql/* $DATADIR
fi

# Ensure mysql owns the DATADIR
chown -R mysql $DATADIR chown root $DATADIR/debian*.flag

# The password for ‘debian-sys-maint’@’localhost’ is auto generated.
# The database inside of DATADIR may not have been generated with this password.
# So, we need to set this for our database to be portable.

echo &#34;Setting password for the &#39;debian-sys-maint&#39;@&#39;localhost&#39; user&#34; /etc/init.d/mysql start sleep 1 DB_MAINT_PASS=$(cat /etc/mysql/debian.cnf |grep -m 1 &#34;password\s&amp;lt;i&amp;gt;=\s&#34;&amp;lt;/i&amp;gt;| sed &#39;s/^password\s&amp;lt;i&amp;gt;=\s&amp;lt;/i&amp;gt;//&#39;) mysql -u root -e \ &#34;GRANT ALL PRIVILEGES ON &amp;lt;i&amp;gt;.&amp;lt;/i&amp;gt; TO &#39;debian-sys-maint&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;$DB_MAINT_PASS&#39;;&#34;

# Create the superuser named ‘docker’.

mysql -u root -e \ “DELETE FROM mysql.user WHERE user = ‘docker’; CREATE USER ‘docker’@’localhost’ IDENTIFIED BY ‘docker’; GRANT ALL PRIVILEGES ON &amp;lt;i&amp;gt;.&amp;lt;/i&amp;gt; TO ‘docker’@’localhost’ WITH GRANT OPTION; CREATE USER ‘docker’@‘%’ IDENTIFIED BY ‘docker’; GRANT ALL PRIVILEGES ON &amp;lt;i&amp;gt;.&amp;lt;/i&amp;gt; TO ‘docker’@‘%’ WITH GRANT OPTION;” &amp;&amp; \
 /etc/init.d/mysql stop

# Start MariaDB

echo &#34;Starting MariaDB…&#34; /usr/bin/mysqld_safe &lt;/pre&gt;

&lt;p&gt;Build it and run it with volumes from the &lt;strong&gt;my-data-container&lt;/strong&gt;.&lt;/p&gt;

&lt;pre class=&#34;brush: bash; title: ; notranslate&#34; title=&#34;&#34;&gt;docker build -t site-db .
docker run -d -p 3306:3306 -volumes-from my-data-store -name my-site-db site-db &lt;/pre&gt;

&lt;p&gt;So up to now we have a MariaDB saving data on a /data/mysql folder shared from another container.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Apache2 &amp;#8211; php container&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This is the main container which will actually serve the Jommla website. This container will have two services running: &lt;strong&gt;httpd and sshd&lt;/strong&gt;. &lt;a href=&#34;http://supervisord.org/&#34;&gt;Supervisord&lt;/a&gt; will be in charge of starting both services and keep them running. Dockerfile:&lt;/p&gt;

&lt;pre class=&#34;brush: bash; title: ; notranslate&#34; title=&#34;&#34;&gt;FROM ubuntu:precise

MAINTAINER Thinking Code &amp;lt;a href=&#34;http://thinkingco.de/&#34;&amp;gt;&amp;lt;&amp;lt;/a&amp;gt;tommaso@thinkingco.de&amp;gt;

# Hack for initctl not being available in Ubuntu
RUN dpkg-divert –local –rename –add /sbin/initctl
RUN ln -s /bin/true /sbin/initctl

# Install all that’s needed
RUN echo “deb http://archive.ubuntu.com/ubuntu precise main universe” &amp;gt; /etc/apt/sources.list &amp;&amp; \
    apt-get update &amp;&amp; apt-get -y upgrade &amp;&amp; \
    DEBIAN_FRONTEND=noninteractive apt-get -y install mysql-client apache2 libapache2-mod-php5 pwgen python-setuptools vim-tiny php5-mysql openssh-server sudo php5-ldap unzip &amp;&amp; \
    apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/*

RUN easy_install supervisor

# Add all config and start files
ADD ./start.sh /start.sh
ADD ./foreground.sh /etc/apache2/foreground.sh
ADD ./supervisord.conf /etc/supervisord.conf
RUN mkdir -p /var/log/supervisor /var/run/sshd
RUN chmod 755 /start.sh &amp;&amp; chmod 755 /etc/apache2/foreground.sh

# Set Apache user and log
ENV APACHE_RUN_USER www-data
ENV APACHE_RUN_GROUP www-data
ENV APACHE_LOG_DIR /var/log/apache2

VOLUME [“/data”]

# Add site to apache

ADD ./pcsnetweb /etc/apache2/sites-available/
RUN a2ensite pcsnetweb

# Set root password to access through ssh
RUN echo &#34;root:myroootpwd” |chpasswd

# Expose web and ssh
EXPOSE 80
EXPOSE 22

CMD [“/bin/bash”, “/start.sh”]&lt;/pre&gt;

&lt;p&gt;In addition to the Dockerfile there are several files needed to set everything up: an apache virtual host file, a file to start apache in foreground and a configuration file for supervisor. Then a start file to sum everything up and all the website files. Being a Joomla migration I only have a kickstarter.php and the jpa archive to restore everything from an akeebabackup.&lt;/p&gt;

&lt;p&gt;So here we have the relevant part of the &lt;strong&gt;supervisord.conf&lt;/strong&gt;:&lt;/p&gt;

&lt;pre class=&#34;brush: bash; title: ; notranslate&#34; title=&#34;&#34;&gt;[program:httpd]
command=/etc/apache2/foreground.sh
stopsignal=6
;sshd
[program:sshd]
command=/usr/sbin/sshd -D
stdout_logfile=/var/log/supervisor/%(program_name)s.log
stderr_logfile=/var/log/supervisor/%(program_name)s.log
autorestart=true &lt;/pre&gt;

&lt;p&gt;The foreground.sh:&lt;/p&gt;

&lt;pre class=&#34;brush: bash; title: ; notranslate&#34; title=&#34;&#34;&gt;&amp;lt;b&amp;gt;!/bin/bash&amp;lt;/b&amp;gt;

read pid cmd state ppid pgrp session tty_nr tpgid rest &amp;lt; /proc/self/stat trap “kill -TERM -$pgrp; exit” EXIT TERM KILL SIGKILL SIGTERM SIGQUIT

source /etc/apache2/envvars
apache2 -D FOREGROUND &lt;/pre&gt;

&lt;p&gt;The start.sh:&lt;/p&gt;

&lt;pre class=&#34;brush: bash; title: ; notranslate&#34; title=&#34;&#34;&gt;&amp;lt;b&amp;gt;!/bin/bash&amp;lt;/b&amp;gt;

if [ -d /data/www ]; then
  cp ./site-mysite.jpa /data/www/
  cp ./kickstart-core–3.8.0.zip /data/www/
fi
if [ -f /data/www/kickstart-core–3.8.0.zip ]; then
  cd /data/www &amp;&amp; unzip kickstart-core–3.8.0.zip
  rm kickstart-core–3.8.0.zip
  cp kickstart-core–3.8.0/* .
  rm -rf kickstart-core–3.8.0
fi
chown www-data:www-data /data/www
supervisord -n &lt;/pre&gt;

&lt;p&gt;Now build and run it:&lt;/p&gt;

&lt;pre class=&#34;brush: bash; title: ; notranslate&#34; title=&#34;&#34;&gt;docker build -t web-machine .
docker run -d -name my-web-machine -p 80:80 -p 9000:22 -link my-site-db:mysql -volumes-from my-data-store web-machine &lt;/pre&gt;

&lt;p&gt;I then needed to copy the temporary beckup files into the /data/www directory which can be done finding the actual dir with the&lt;/p&gt;

&lt;pre class=&#34;brush: bash; title: ; notranslate&#34; title=&#34;&#34;&gt;docker inspect my-data-store | grep data&lt;/pre&gt;

&lt;p&gt;command which will give use the actual /data/www path on the host machine.&lt;/p&gt;

&lt;p&gt;I then moved there the two needed file for restoring Joomla from an Akeeba backup: 1. a site-mysite–20131230–162721.jpa file containing all db data and files 2. kickstart-core–3.8.0.zip containing the kickstarter.php page to restore the backup&lt;/p&gt;

&lt;p&gt;I’m doing this manually and not through a Dockerfile because it will be needed only the first time and not on every container start up.&lt;/p&gt;

&lt;p&gt;So now we have all the db data in the my-data-store /data/mysql dir, all the website data in the my-data-store /data/www dir thus having a full backup can be achieved also with rsync on the /data dir.&lt;/p&gt;

&lt;p&gt;We can also access the Apache2 PHP container through ssh using the host ip address on port 9000 and from inside the Apache container connect to the MariaDB through mysql client.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deploy Rails with Docker, Part 2</title>
      <link>http://thinkingco.de/techblog/deploy-rails-with-docker-part-2/</link>
      <pubDate>Sat, 04 Jan 2014 02:33:24 &#43;0000</pubDate>
      
      <guid>http://thinkingco.de/techblog/deploy-rails-with-docker-part-2/</guid>
      <description>

&lt;p&gt;Series takeaways:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Configure a Rails app to be deployed on a cloud architecture (Part 1)&lt;/li&gt;
&lt;li&gt;Create a vagrant test machine with docker installed (Part 1)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Interactive image building vs. Dockerfiles (Part 2)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data Persistence (Part 2)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Good Practices (Part 2)&lt;/strong&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Create 7 docker containers that will host the reconfigured rails app (Part 3):&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Container 1: Redis Server (for session storing)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;ul&gt;
&lt;li&gt;Container 2: Fluentd (log collection)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;ul&gt;
&lt;li&gt;Container 3: ElasticSearch (log storage)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;ul&gt;
&lt;li&gt;Container 4: Kibana (log analysis)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;ul&gt;
&lt;li&gt;Container 5: PostgreSQL + PostGIS&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;ul&gt;
&lt;li&gt;Container 6: Chruby Ruby Rails Puma&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;ul&gt;
&lt;li&gt;Container 7: Nginx&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Link the 7 containers through &lt;a href=&#34;http://blog.docker.io/tag/links/&#34;&gt;Docker Links&lt;/a&gt; (Part 3) ‚Äî&amp;gt; intra host communication&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Real Docker Playground with two hosts (Part 4)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Deploy PostgreSQL on this second host (Part 4)&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Make the app work with the second host postgres container (Part 4) ‚Äî&amp;gt; inter host communication&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;SCALE (Part 5)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Automatic Service Discovery with &lt;a href=&#34;https://github.com/skynetservices/skydns&#34;&gt;Skydns&lt;/a&gt; and &lt;a href=&#34;https://github.com/crosbymichael/skydock&#34;&gt;Skydock&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;*   Session data and Logs HA&lt;/li&gt;

&lt;li&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Database HA&lt;/p&gt;

&lt;h2 id=&#34;toc_0&#34;&gt;Interactive image building vs Dockerfiles&lt;/h2&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;It is possible to create docker images either interactively or through a Dockerfile.&lt;/p&gt;

&lt;p&gt;To clarify this I‚Äôll show how to create a Redis Server in both ways.&lt;/p&gt;

&lt;h3 id=&#34;toc_1&#34;&gt;Container 1: Redis Server&lt;/h3&gt;

&lt;p&gt;We need to login into the vagrant machine to begin working with our containers
  `&lt;/p&gt;

&lt;p&gt;&lt;pre&gt;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34; title=&#34;&#34;&gt;vagrant ssh&lt;/pre&gt;&lt;/p&gt;

&lt;h4 id=&#34;toc_2&#34;&gt;Manual build process&lt;/h4&gt;

&lt;p&gt;Using the vagrant docker image docker will already be running in daemon mode.&lt;/p&gt;

&lt;p&gt;To run a container from the base ubuntu image:&lt;/p&gt;

&lt;p&gt;&lt;pre&gt;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34; title=&#34;&#34;&gt;sudo docker run -i -t ubuntu /bin/bash&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;This will run a container in interactive (-i) mode with a pseudo tty (-t) and give us a /bin/bash terminal to use inside the container.
  The container will be spawned from an image, the base ubuntu image which will be automatically downloaded if not found locally.&lt;/p&gt;

&lt;p&gt;The command will give us access to the newly spawned container as root.&lt;/p&gt;

&lt;p&gt;We will then be able to issue all the needed commands to setup the desired service in the following example the redis server:&lt;/p&gt;

&lt;p&gt;&lt;pre&gt;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34; title=&#34;&#34;&gt;&amp;lt;br /&amp;gt;&amp;lt;%%KEEPWHITESPACE%%&amp;gt; echo &amp;quot;deb &lt;a href=&#34;http://archive.ubuntu.com/ubuntu&#34;&gt;http://archive.ubuntu.com/ubuntu&lt;/a&gt; precise main universe&amp;quot; &amp;amp;gt; /etc/apt/sources.list&amp;lt;br /&amp;gt;&amp;lt;%%KEEPWHITESPACE%%&amp;gt; apt-get update&amp;lt;br /&amp;gt;&amp;lt;%%KEEPWHITESPACE%%&amp;gt; apt-get install -y redis-server&amp;lt;br /&amp;gt;&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;The base redis machine is ready let‚Äôs commit it and save it as an image to be able to spawn it multiple times as needed.&lt;/p&gt;

&lt;p&gt;Send ctrl-p + ctrl-q to exit the container shell (if you forgot something just &lt;code&gt;sudo docker attach &amp;lt;container_id&amp;gt;&lt;/code&gt;) and then run:&lt;/p&gt;

&lt;p&gt;&lt;pre&gt;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34; title=&#34;&#34;&gt;sudo docker commit &amp;amp;lt;container_id&amp;amp;gt; &amp;amp;lt;some_name&amp;amp;gt;&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;If you simply &lt;code&gt;exit&lt;/code&gt; the container shell the container will shut down.&lt;/p&gt;

&lt;h4 id=&#34;toc_3&#34;&gt;Dockerfile&lt;/h4&gt;

&lt;p&gt;The docker build process of a Dockerfile has the following logical steps:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;spawn a container from an image (because images are immutable)

&lt;ol&gt;
&lt;li&gt;run shell scripts inside the container&lt;/li&gt;
&lt;li&gt;save the result: commit the container as an intermediate image&lt;/li&gt;
&lt;li&gt;proceed to next build step&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;A &lt;code&gt;Dockerfile&lt;/code&gt; is a shell inspired script supporting &lt;a href=&#34;http://docs.docker.io/en/latest/use/builder/&#34;&gt;few instructions&lt;/a&gt; that describes the &lt;code&gt;docker build&lt;/code&gt; process.&lt;/p&gt;

&lt;p&gt;Here is the same redis server machine expressed with a Dockerfile:&lt;/p&gt;

&lt;p&gt;&lt;pre&gt;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34; title=&#34;&#34;&gt;&amp;lt;br /&amp;gt;FROM ubuntu:precise&amp;lt;br /&amp;gt;RUN apt-get update&amp;lt;br /&amp;gt;RUN apt-get -y install redis-server&amp;lt;br /&amp;gt;EXPOSE 6379&amp;lt;br /&amp;gt;ENTRYPOINT [&amp;quot;/usr/bin/redis-server&amp;quot;]&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;You can also leverage the wonderful docker community and pull a ready-to-go image from the Docker index:&lt;/p&gt;

&lt;p&gt;&lt;pre&gt;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34; title=&#34;&#34;&gt;docker pull dockerfile/redis&lt;/pre&gt;&lt;/p&gt;

&lt;h2 id=&#34;toc_4&#34;&gt;Data Persistence&lt;/h2&gt;

&lt;p&gt;As &lt;strong&gt;containers are ephemeral&lt;/strong&gt; two problems arises:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Data Persistence&lt;/strong&gt; across containers restart&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Network configuration persistence or predictability&lt;/strong&gt; across containers restart&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I‚Äôll deal here about the first issue and in &lt;em&gt;Part 4&lt;/em&gt; about the latter.&lt;/p&gt;

&lt;p&gt;Data persistence can be implemented in Docker essentially in three ways:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Sharing a volume between a container and the host&lt;/li&gt;
&lt;li&gt;Decoupling data within each container creating a volume&lt;/li&gt;
&lt;li&gt;Sharing one or more containers as the data volume hoders between one or more containers&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The first and second implementations are as easy as:&lt;/p&gt;

&lt;p&gt;&lt;pre&gt;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34; title=&#34;&#34;&gt;sudo docker run -v /var/logs:/var/host_logs:ro ubuntu bash&lt;/pre&gt;
  &lt;pre class=&#34;brush: bash; title: ; notranslate&#34; title=&#34;&#34;&gt;sudo docker run -v /var/new_volume ubuntu bash&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;with the &lt;code&gt;-v&lt;/code&gt; option taking the following parameters:&lt;/p&gt;

&lt;p&gt;&lt;pre&gt;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34; title=&#34;&#34;&gt;-v=[]: Create a bind mount with: [host-dir]:[container-dir]:[rw|ro].&amp;lt;br /&amp;gt;If &amp;quot;host-dir&amp;quot; is missing, then docker creates a new volume.&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;The Docker documentation explains very well why sharing volumes with the host is not good:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;This is not available from a Dockerfile as it makes the built image less portable or shareable. [host-dir] volumes are 100% host dependent and will break on any other machine.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;To obtain &lt;strong&gt;data decouplication&lt;/strong&gt; you can also add a &lt;code&gt;VOLUME&lt;/code&gt;directive to an image Dockerfile and this will automatically create a new volume.
  Data in the volume is not destroyed with the container but will persist in a &lt;code&gt;/var/lib/docker/dir/vfs/container_id&lt;/code&gt; folder that you can grabo with a &lt;code&gt;docker inspect&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The third implementation is almost easy as the first two but has the portability/shareability advantage we need. It is a &lt;strong&gt;data decouplication&lt;/strong&gt; run through an intermediate container. A sort of &lt;em&gt;container-in-the-middle&lt;/em&gt; that while persisting data can also be easily ported to another host.&lt;/p&gt;

&lt;p&gt;You can create a data container like this:&lt;/p&gt;

&lt;p&gt;&lt;pre&gt;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34; title=&#34;&#34;&gt;docker run -v /data/www -v /data/db busybox true&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;p&gt;&lt;pre&gt;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34; title=&#34;&#34;&gt;&amp;lt;/pre&amp;gt;&amp;lt;h1&amp;gt;BUILD-USING: docker build -t data .&amp;lt;/h1&amp;gt;&amp;lt;h1&amp;gt;RUN-USING: docker run -name DATA data&amp;lt;/h1&amp;gt;&amp;lt;pre&amp;gt;&amp;lt;br /&amp;gt;FROM busybox&amp;lt;br /&amp;gt;VOLUME [‚Äú/data/www‚Äù, ‚Äú/data/db‚Äù]&amp;lt;br /&amp;gt;CMD [&amp;quot;true&amp;quot;]&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;As any container needs a command to run, &lt;code&gt;true&lt;/code&gt; is the smallest, simplest program that you can run. Running the true command will immediately exit the container but &lt;strong&gt;once created you can mount its volumes in any other container using the &lt;code&gt;-volumes-from&lt;/code&gt; option; irrespecive of whether the container is running or not.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;busybox&lt;/strong&gt; is a wonderful linux image ASACB (as small as can be) ~ 2.5 MB!!!&lt;/p&gt;

&lt;p&gt;What can you do with this &lt;strong&gt;DATA CONTAINER&lt;/strong&gt; pattern?&lt;/p&gt;

&lt;p&gt;You can create exactly what the name implies: data containers.&lt;/p&gt;

&lt;p&gt;You can create as much containers as you like, one data container for each process or one for the process and one for ist logs or one for all processes data and one for all processes logs.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This creates a data container with &lt;code&gt;/data&lt;/code&gt; volume exposed&lt;/p&gt;

&lt;p&gt;&lt;pre&gt;&lt;pre class=&#34;brush: bash; title: ; notranslate&#34; title=&#34;&#34;&gt;docker run -v /data &amp;ndash;name PGDATA tcode/datastore&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;This binds the actual process (PostgreSQL) to the data container (you need to configure the postgresql.conf accordingly):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;pre&amp;gt;&amp;lt;pre class=&amp;quot;brush: bash; title: ; notranslate&amp;quot; title=&amp;quot;&amp;quot;&amp;gt;docker run -d --volumes-from PGDATA --name pg93 tcode/pg93&amp;lt;/pre&amp;gt;

Now whatever happens to your pg93 container your data will be safe in your PGDATA container.
If you restart your server when the pg93 container will restart it will find all its data into PGDATA again.

More interestingly if you need to migrate your data to a new host you can do:

&amp;lt;pre&amp;gt;&amp;lt;pre class=&amp;quot;brush: bash; title: ; notranslate&amp;quot; title=&amp;quot;&amp;quot;&amp;gt;docker run -rm --volumes-from PGDATA -v $(pwd):/backup busybox tar cvf /backup/backup.tar /data&amp;lt;/pre&amp;gt;

                                                                                                             This will start a container which will mount the current dir in /backup and load volumes from PGDATA, then it will tar all the data in /data in a comfortable backup.tar file you will find on your current path at container exit!

                                                                                                             Now you can go to another host and recreate your PGDATA data container in the new host:

                                                                                                             &amp;lt;pre&amp;gt;&amp;lt;pre class=&amp;quot;brush: bash; title: ; notranslate&amp;quot; title=&amp;quot;&amp;quot;&amp;gt;docker run -v /data --name PGDATA tcode/datastore&amp;lt;/pre&amp;gt;

                                                                                                             inject the data back in the data container:

                                                                                                             &amp;lt;pre&amp;gt;&amp;lt;pre class=&amp;quot;brush: bash; title: ; notranslate&amp;quot; title=&amp;quot;&amp;quot;&amp;gt;docker run -rm --volumes-from PGDATA -v $(pwd):/backup busybox tar xvf /backup/backup.tar / &amp;lt;/pre&amp;gt;

                                                                                                                                                                                                                          Start your shiny new postgresql server with all your data:

                                                                                                                                                                                                                          &amp;lt;pre&amp;gt;&amp;lt;pre class=&amp;quot;brush: bash; title: ; notranslate&amp;quot; title=&amp;quot;&amp;quot;&amp;gt;docker run -d --volumes-from PGDATA --name pg93 tcode/pg93&amp;lt;/pre&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;toc_5&#34;&gt;Good Practices&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;                                                                                                                                                                                                                          The different kind of data persistence are interesting because they offer hints on how to do things properly in docker.
                                                                                                                                                                                                                          In this respect docker is not only a commodity over lxcs but is actually shaping up a new way of developing and deploying applications.
                                                                                                                                                                                                                          Using this wonderful piece of software bring about the need of some new practices.
                                                                                                                                                                                                                          For example:
                                                                                                                                                                                                                          &amp;amp;#8211; How can I keep my git development process and merge it with docker?
                                                                                                                                                                                                                          &amp;amp;#8211; How can I migrate an existing development/deployment situation to docker?

                                                                                                                                                                                                                          Answers will widely vary depending on which technologies you are using.

                                                                                                                                                                                                                          My actual development environment is osx/zsh/git/vim.
                                                                                                                                                                                                                          I‚Äôm developing with Rails.
                                                                                                                                                                                                                          So my actual development involves process is to change files commit them and then deploy them in production through Capistrano.

                                                                                                                                                                                                                          How can this change with docker?

                                                                                                                                                                                                                          Actually I have VirtualBox installed with Vagrant and my development workflow is the following:
                                                                                                                                                                                                                          1. In Vagrant:
                                                                                                                                                                                                                          &amp;amp;#8211; Start a database container
                                                                                                                                                                                                                          &amp;amp;#8211; Start an interactive rails container like this: `docker run -i -t -v /vagrant/rails_app:/data --link databasecontainer:db -p 80:3000 my_rails_image /bin/bash`
                                                                                                                                                                                                                          &amp;amp;#8211; Run the rails server after proper initialization: `cd /data &amp;amp;&amp;amp; bundle install &amp;amp;&amp;amp; rails s Puma`
                                                                                                                                                                                                                          2. In my OSX:
                                                                                                                                                                                                                          &amp;amp;#8211; `vim /rails_app`
                                                                                                                                                                                                                          &amp;amp;#8211; hack hack hack
                                                                                                                                                                                                                          3. In Vagrant container: CTRL+C rails s Puma
                                                                                                                                                                                                                          4. In my OSX `git push`

                                                                                                                                                                                                                          And what about deployment?

                                                                                                                                                                                                                          Deplyoment for a 12 factor app which is already configured to have minimal difference between development and production environments is quite straightforward, the only thing to take care of is getting your code from your git of choice repository:

                                                                                                                                                                                                                          GitHub

                                                                                                                                                                                                                          &amp;lt;pre&amp;gt;&amp;lt;pre class=&amp;quot;brush: bash; title: ; notranslate&amp;quot; title=&amp;quot;&amp;quot;&amp;gt;curl -sLk -u $REPO_TOKEN:x-oauth-basic https://github.com/$REPO_USER/$REPO_NAME/archive/master.tar.gz -o master.tar.gz&amp;lt;/pre&amp;gt;

                                                                                                                                                                                                                          Bitbucket

                                                                                                                                                                                                                          &amp;lt;pre&amp;gt;&amp;lt;pre class=&amp;quot;brush: bash; title: ; notranslate&amp;quot; title=&amp;quot;&amp;quot;&amp;gt;curl --digest --user $REPO_USER:$REPO_PASSWORD https://bitbucket.org/$REPO_USER/$REPO_NAME/get/master.tar.gz -o master.tar.gz&amp;lt;/pre&amp;gt;

                                                                                                                                                                                                                          More on this in Part 3 which will show the different Dockerfiles.

                                                                                                                                                                                                                          DATA PERSISTENCE AND DECOUPLICATION:
                                                                                                                                                                                                                          [http://docs.docker.io/use/working_with_volumes/](http://docs.docker.io/use/working_with_volumes/)
                                                                                                                                                                                                                          [http://www.offermann.us/2013/12/tiny-docker-pieces-loosely-joined.html](http://www.offermann.us/2013/12/tiny-docker-pieces-loosely-joined.html)
                                                                                                                                                                                                                          [http://www.tech-d.net/2013/12/16/persistent-volumes-with-docker-container-as-volume-pattern/](http://www.tech-d.net/2013/12/16/persistent-volumes-with-docker-container-as-volume-pattern/)
                                                                                                                                                                                                                          [http://stinemat.es/dockerizing-ghost-part‚Äì2-data-migration/](http://stinemat.es/dockerizing-ghost-part‚Äì2-data-migration/)
                                                                                                                                                                                                                          [http://www.techbar.me/wordpress-docker/](http://www.techbar.me/wordpress-docker/)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>2014 thinning list</title>
      <link>http://thinkingco.de/techblog/2014-thinning-list/</link>
      <pubDate>Sat, 04 Jan 2014 02:33:24 &#43;0000</pubDate>
      
      <guid>http://thinkingco.de/techblog/2014-thinning-list/</guid>
      <description>&lt;p&gt;To be faithful to my motto&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Thin code is king code&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I&amp;#8217;m willing to slim down my development/deployment stack.&lt;/p&gt;

&lt;p&gt;This year I will:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Switch from rvm to &lt;a href=&#34;https://github.com/postmodern/chruby&#34;&gt;chruby&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Migrate this blog from WordPress to either &lt;a href=&#34;http://www.locomotivecms.com/&#34;&gt;LocomotiveCMS&lt;/a&gt; or &lt;a href=&#34;http://jekyllrb.com/&#34;&gt;Jeckyll&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Thin down all development and deployment by using &lt;a href=&#34;http://www.docker.io/&#34;&gt;Docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Learn &lt;a href=&#34;http://golang.org/&#34;&gt;Go&lt;/a&gt; (this is just because to thin down code you need to use the thinnest tool available for each task)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Happy coding year.&lt;/p&gt;

&lt;p&gt;P.S. while at it I&amp;#8217;d also like to thin myself a bit &amp;#8230;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deployment Rails with Docker Part 1</title>
      <link>http://thinkingco.de/techblog/deploy-rails-with-docker-part-1/</link>
      <pubDate>Wed, 11 Dec 2013 02:33:24 &#43;0000</pubDate>
      
      <guid>http://thinkingco.de/techblog/deploy-rails-with-docker-part-1/</guid>
      <description>

&lt;p&gt;After my &lt;a href=&#34;http://thinkingco.de/easy-peasy-deploy&#34;&gt;first approach&lt;/a&gt; to easying up the many pains of Rails deployment I happened to bump into &lt;a href=&#34;http://www.docker.io&#34;&gt;Docker&lt;/a&gt; for a broader PAAS project.&lt;/p&gt;

&lt;p&gt;So my thought was: why automate only code deployment if I can automate the whole machine deployment especially with a tool like Docker that makes this task trivial and quick.&lt;/p&gt;

&lt;p&gt;In this way it will be extremely easy to replicate a development/production environment and instead of updating code I could simply redeploy a machine.&lt;br /&gt;
Not only this but it will be easier to experiment with a broader PAAS deployment.&lt;/p&gt;

&lt;p&gt;So these will be the takeaways from this series of posts:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Configure a Rails app to be deployed on a cloud architecture (Part 1)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Create a vagrant test machine with docker installed (Part 1)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Interactive image building vs. Dockerfiles (Part 2)&lt;/li&gt;
&lt;li&gt;Data Persistence (Part 2)&lt;/li&gt;
&lt;li&gt;Development vs. Production (Part 2)&lt;/li&gt;
&lt;li&gt;Create 7 docker containers that will host the reconfigured rails app (Part 3):

&lt;ul&gt;
&lt;li&gt;Container 1: Redis Server (for session storing)&lt;/li&gt;
&lt;li&gt;Container 2: Fluentd (log collection)&lt;/li&gt;
&lt;li&gt;Container 3: ElasticSearch (log storage)&lt;/li&gt;
&lt;li&gt;Container 4: Kibana (log analysis)&lt;/li&gt;
&lt;li&gt;Container 5: PostgreSQL + PostGIS&lt;/li&gt;
&lt;li&gt;Container 6: Ruby 2.1.1 Rails Puma&lt;/li&gt;
&lt;li&gt;Container 7: Nginx&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Link the 7 containers through &lt;a href=&#34;http://blog.docker.io/tag/links/&#34;&gt;Docker Links&lt;/a&gt; (Part 3) —&amp;gt; intra host communication&lt;/li&gt;
&lt;li&gt;Create another vagrant test machine with docker (Part 4)&lt;/li&gt;
&lt;li&gt;Deploy PostgreSQL on this second host (Part 4)&lt;/li&gt;
&lt;li&gt;Make the app work with the second host postgres container (Part 4) —&amp;gt; inter host communication&lt;/li&gt;
&lt;li&gt;SCALE (Part 5)

&lt;ul&gt;
&lt;li&gt;Automatic Service Discovery with &lt;a href=&#34;https://github.com/skynetservices/skydns&#34;&gt;Skydns&lt;/a&gt; and &lt;a href=&#34;https://github.com/crosbymichael/skydock&#34;&gt;Skydock&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Session data and Logs HA&lt;/li&gt;
&lt;li&gt;Database HA&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The overview seems quite interesting so let’s start.&lt;/p&gt;

&lt;h2 id=&#34;toc_0&#34;&gt;Configure a Rails app to be deployed on a cloud architecture&lt;/h2&gt;

&lt;p&gt;To configure the Rails app (or every other app) to be cloud deployable you need to follow the &lt;a href=&#34;12factor.net&#34;&gt;The twelve-factor app methodology&lt;/a&gt;.&lt;br /&gt;
You can use this methodology to build software-as-a-service apps that:&lt;br /&gt;
&amp;#8211; Use declarative formats for setup automation, to minimize time and cost for new developers joining the project;&lt;br /&gt;
&amp;#8211; Have a clean contract with the underlying operating system, offering maximum portability between execution environments;&lt;br /&gt;
&amp;#8211; Are suitable for deployment on modern cloud platforms, obviating the need for servers and systems administration;&lt;br /&gt;
&amp;#8211; Minimize divergence between development and production, enabling continuous deployment for maximum agility;&lt;br /&gt;
&amp;#8211; And can scale up without significant changes to tooling, architecture, or development practices.&lt;/p&gt;

&lt;p&gt;Going through the twelve factors I found that most of the steps are already achieved through git versioning + rails YAY!!!&lt;/p&gt;

&lt;p&gt;Nonetheless there are some points to tackle.&lt;/p&gt;

&lt;h3 id=&#34;toc_1&#34;&gt;Config&lt;/h3&gt;

&lt;p&gt;Rails stores configuration in config files which are not checked into revision control. This violates the principle of &lt;strong&gt;strict separation of config from code&lt;/strong&gt;.&lt;br /&gt;
Configuration must not be grouped (development, test, production) and must be independently managed for each deploy.&lt;br /&gt;
It must be stored in &lt;strong&gt;&lt;em&gt;environment variables&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;So what we need is a place to store env variables which won’t be committed into our git repository and a way to load it into Rails.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&#34;https://github.com/bkeepers/dotenv&#34;&gt;dotenv gem&lt;/a&gt; is a wellcomed help in this task expecially in its master branch which now initializes before database (&lt;a href=&#34;https://github.com/laserlemon/figaro/issues/70&#34;&gt;see here&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;The dotenv gem let you use a &lt;code&gt;.env&lt;/code&gt;file to store ENV variables (you can also use a different &lt;code&gt;.env.environment&lt;/code&gt; file for each environment though this will break the twelve factor app principles)&lt;/p&gt;

&lt;p&gt;Something like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;S3_BUCKET=YOURS3BUCKET
SECRET_KEY=YOURSECRETKEYGOESHERE
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That you can use in your code this way:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;config.fog_directory  = ENV[&#39;S3_BUCKET&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Every time the rails app loads it will have all the variables declared in &lt;code&gt;.env&lt;/code&gt; available in &lt;code&gt;ENV&lt;/code&gt;!&lt;/p&gt;

&lt;h3 id=&#34;toc_2&#34;&gt;Processes&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Twelve-factor processes are stateless and share-nothing&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Amongst other things this means we need to store our session data either in the DB or in another kind of datastore.&lt;br /&gt;
Using the db will introduce significant lag in page rendering so I want to use a faster key/value datastore.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://memcached.org/&#34;&gt;Memcached&lt;/a&gt; is a very interesting and clusterable datastore but I will use &lt;strong&gt;&lt;a href=&#34;http://redis.io/&#34;&gt;Redis&lt;/a&gt;&lt;/strong&gt; for two fundamental reasons:&lt;br /&gt;
1. first and foremost because its creator is italian!&lt;br /&gt;
2. faster than memcached&lt;br /&gt;
3. more powerful commands&lt;br /&gt;
4. no cache warmup needed&lt;br /&gt;
5. useful for solving other problems (eg. queues with Resque)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/roidrage/redis-session-store&#34;&gt;redis-session-store&lt;/a&gt; to the rescue!&lt;/p&gt;

&lt;p&gt;Once installed and run a Redis server switching Rails session management to Redis is as simple as&lt;br /&gt;
adding a dependency on the redis-session-store gem to your Gemfile then run bundle.&lt;/p&gt;

&lt;p&gt;Open the session initializer &lt;code&gt;config/initializers/session_store.rb&lt;/code&gt; and add the following lines:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;AppName::Application.config.session_store :redis_session_store, {
  key: &#39;redis_session&#39;,
  redis: {
    db: 2,
    expire_after: 120.minutes,
    key_prefix: &#39;appname:session:&#39;,
    host: ENV[&amp;quot;REDIS_PORT_6379_TCP_ADDR&amp;quot;], # Redis host name, default is localhost
    port: ENV[&amp;quot;REDIS_PORT_6379_TCP_PORT&amp;quot;]   # Redis port, default is 6379
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Restart the server and you&amp;#8217;re ready to go!&lt;/p&gt;

&lt;h3 id=&#34;toc_3&#34;&gt;Keep development, staging, and production as similar as possible&lt;/h3&gt;

&lt;p&gt;Using Docker on Vagrant on my development machine means that my development and production environments will be identical!&lt;/p&gt;

&lt;h3 id=&#34;toc_4&#34;&gt;Treat logs as event streams&lt;/h3&gt;

&lt;p&gt;While rails is already configured to log &lt;code&gt;stdout&lt;/code&gt; to terminal when in development mode it is not thought to route events to a standard destination for long term archiving.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://fluentd.org/&#34;&gt;Fluentd&lt;/a&gt; is an open source log router (written in ruby) which can used to route log streams to a permanent storing location (MongoDB or a PostgreSQL hstore to avoid inserting another piece of software in the overall architecture, or ElasticSearch to analyze log data) and which includes a robust buffering solution.&lt;/p&gt;

&lt;p&gt;Using fluentd in a Rails 4 can be achieved through the following steps:&lt;br /&gt;
1. &lt;a href=&#34;http://docs.fluentd.org/articles/before-install&#34;&gt;Prepare the OS&lt;/a&gt;&lt;br /&gt;
2. &lt;a href=&#34;http://docs.fluentd.org/articles/install-by-deb&#34;&gt;Install fluentd (Debian flavor)&lt;/a&gt;&lt;br /&gt;
3. Add fluent logger gem to rails app&lt;br /&gt;
gem &amp;#8216;act-fluent-logger-rails&amp;#8217;&lt;br /&gt;
bundle&lt;br /&gt;
4. Configure rails to log through fluentd&lt;br /&gt;
&amp;#8211; in config/environments/production.rb&lt;br /&gt;
config.log_level = :info&lt;br /&gt;
config.logger = ActFluentLoggerRails::Logger.&lt;br /&gt;
new()&lt;br /&gt;
&amp;#8211; create a config/fluent-logger.yml file&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;production:
  fluent_host:   ‘192.168.x.x’
  fluent_port:   24224
  tag:           &#39;foo&#39;
  messages_type: &#39;string&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;toc_5&#34;&gt;Create a vagrant test machine with docker installed&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&#34;http://docs.docker.io/en/latest/installation/vagrant/&#34;&gt;Docker guide&lt;/a&gt; works flawlessy and deploys a vagrant image through a Dockerfile deploying docker through docker &amp;#8230; awesome!&lt;/p&gt;

&lt;p&gt;The Docker version actually deployed is 0.6.1 I need to upgrade to use the &lt;strong&gt;links&lt;/strong&gt; functionality available from 0.6.5.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install curl
# Add the Docker repository key to your local keychain
sudo sh -c &amp;quot;curl https://get.docker.io/gpg | apt-key add -&amp;quot;
# Add the Docker repository to your apt sources list.
sudo sh -c &amp;quot;echo deb https://get.docker.io/ubuntu docker main &amp;gt; /etc/apt/sources.list.d/docker.list&amp;quot;
# update your sources list
sudo apt-get update
# install the latest
sudo apt-get install lxc-docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;DONE!&lt;/p&gt;

&lt;p&gt;That was easy!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;This ends Part 1.&lt;/strong&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Easy Peasy Deploy</title>
      <link>http://thinkingco.de/techblog/easy-peasy-deploy/</link>
      <pubDate>Thu, 14 Nov 2013 02:33:24 &#43;0000</pubDate>
      
      <guid>http://thinkingco.de/techblog/easy-peasy-deploy/</guid>
      <description>&lt;p&gt;I&amp;#8217;m a bit tired of reinventing the wheel every time I need to deploy a rails app.&lt;/p&gt;

&lt;p&gt;Capistrano has made the good decision to use rake instead of his own DSL so I&amp;#8217;ll follow that path.&lt;/p&gt;

&lt;p&gt;I need a &lt;code&gt;deploy.rake&lt;/code&gt; file with some tasks inside.&lt;/p&gt;

&lt;p&gt;I want to be able to perform ssh commands but I&amp;#8217;d also like a good DSL for this so I ended up using the &lt;a href=&#34;https://github.com/capistrano/sshkit&#34; target=&#34;_blank&#34;&gt;same tool Capistrano uses: sshkit&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It is a very lightweight gem with some good syntactic sugar for ssh commands.&lt;br /&gt;
It basically has four commands that wraps ssh and system commands.&lt;br /&gt;
We can see the use of run_locally and capture in the following task.&lt;/p&gt;

&lt;pre class=&#34;brush: ruby; title: ; notranslate&#34; title=&#34;&#34;&gt;# run_locally runs a command on your local machine
  # useful if you need to add LOCAL machine pub key to REMOTE machine authorized_keys if not present
     run_locally do         
        within &#39;~&#39; do        
          remote_authorized_keys = capture(&#34;ssh #{MY.deploy_user}@#{MY.machine} &#39;cat ~/.ssh/authorized_keys&#39;&#34;)
          # capture as its name implies captures the stdout of the command and returns a String
          # you can check to see if the the keys include your key
          if !remote_authorized_keys.include?(capture(&#34;cat ~/.ssh/id_rsa.pub&#34;))
            execute(&#34;cat ~/.ssh/id_rsa.pub | ssh #{MY.deploy_user}@#{MY.machine} &#39;mkdir ~/.ssh; cat &amp;gt;&amp;gt; ~/.ssh/authorized_keys&#39;&#34;)
          end
        end
     end
&lt;/pre&gt;

&lt;p&gt;The other two commands &lt;code&gt;test&lt;/code&gt; and &lt;code&gt;execute&lt;/code&gt; works together in the following task:&lt;/p&gt;

&lt;pre class=&#34;brush: ruby; title: ; notranslate&#34; title=&#34;&#34;&gt;# test returns true or false
  unless test &#34;[ -d /var/rails ]&#34;
      # execute runs the command
      # accepted syntax --&amp;gt; :sudo, :mkdir, :rails || &#34;sudo mkdir rails&#34; or :sudo, &#34;mkdir #{MY.deploy_to}&#34;
      execute :sudo, :mkdir, :rails   
  end
&lt;/pre&gt;

&lt;p&gt;Armed with sshkit and my understanding of what a simple rails deployment has to do I ended up with the following ideas about my deploy.rake.&lt;/p&gt;

&lt;p&gt;It will be split into several files:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Machine Preparation&lt;/li&gt;
&lt;li&gt;Db setup (with specific file for every supported db starting with PostgreSQL)&lt;/li&gt;
&lt;li&gt;Deploy with Git&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I&amp;#8217;m starting with the Deploy part. I&amp;#8217;m assuming the following: use of rvm and Ubuntu 12.04. In any case migrating to different tools should not be too painful!&lt;/p&gt;

&lt;p&gt;The Deploy script will have three basic tasks:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;deploy:setup&lt;/li&gt;
&lt;li&gt;deploy:update&lt;/li&gt;
&lt;li&gt;deploy:rollback&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;deploy:setup will&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;clone the repo&lt;/li&gt;
&lt;li&gt;run bundle install&lt;/li&gt;
&lt;li&gt;run db:migrate and db:seed&lt;/li&gt;
&lt;li&gt;run assets:precompile&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;deploy:update will:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;fetch the last commit&lt;/li&gt;
&lt;li&gt;run bundle install if Gemfile is changed&lt;/li&gt;
&lt;li&gt;run db:migrate if database.yml or db/ folder changed&lt;/li&gt;
&lt;li&gt;run assets:precompile if assets/ folder changed&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;deploy:rollback will:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;check and store if Gemfile, db or assets changed&lt;/li&gt;
&lt;li&gt;rollback db if changed&lt;/li&gt;
&lt;li&gt;revert to previous commit (git back, git back &amp;#8230; git back to where you once belonged)&lt;/li&gt;
&lt;li&gt;bundle install if Gemfile was different&lt;/li&gt;
&lt;li&gt;assets precompile if assets were different&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It is not easy to be able to use a remote environment configuration (included a modified $PATH) in ssh (useful if you are in need to use a specifically installed ruby version).&lt;/p&gt;

&lt;p&gt;This is because when you are deploying an app ssh won&amp;#8217;t use an interactive shell but a &lt;strong&gt;non interactive&lt;/strong&gt; one. This means that you basically lose all the &lt;code&gt;.profile .bash_profile .bashrc&lt;/code&gt; configurations.&lt;/p&gt;

&lt;p&gt;To be able to add path and env options to your non interactive shell the only solution (please advice if you have another way to do it) seems to edit &lt;code&gt;/etc/ssh/sshd_config&lt;/code&gt;, and uncomment this line:&lt;/p&gt;

&lt;pre class=&#34;brush: bash; title: ; notranslate&#34; title=&#34;&#34;&gt;PermitUserEnvironment yes
&lt;/pre&gt;

&lt;p&gt;Configure the environment you want to be loaded in &lt;code&gt;$HOME/.ssh/environment&lt;/code&gt; and restart sshd.&lt;/p&gt;

&lt;p&gt;This works well but leaves a potential security hole in your machine. This is why I&amp;#8217;m evaluating if it is possible to wrap the needing calls in two tasks that will change the sshd configuration and revert it back. For now I&amp;#8217;ll leave it configured this way.&lt;/p&gt;

&lt;p&gt;The first problem I need to face is how to share configuration parameters between rake files.&lt;/p&gt;

&lt;p&gt;I want to be able to split rake files to have a single file for each concern: &lt;code&gt;machine.rake deploy.rake database.rake&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;This means that I need to require all those files in my main rake file like this:&lt;/p&gt;

&lt;pre class=&#34;brush: ruby; title: ; notranslate&#34; title=&#34;&#34;&gt;# Load all tasks from easy_peasy dir
Dir[&#39;./easy_peasy/*.rake&#39;].each{ |f| require f }
&lt;/pre&gt;

&lt;p&gt;Requiring files means I can&amp;#8217;t use local variables to store configuration data because they won&amp;#8217;t be available.&lt;/p&gt;

&lt;p&gt;So I ended up opting for an OpenStruct which enables options definition on the fly, instantiated in a constant available through files:&lt;/p&gt;

&lt;pre class=&#34;brush: ruby; title: ; notranslate&#34; title=&#34;&#34;&gt;# Configuration data put in an OpenStruct constant 
  # to make them available to all rake files
  MY = OpenStruct.new
  MY.machine = &#39;machine_ip_or_dns&#39;
  MY.deploy_user = &#39;deployer&#39;
  MY.deploy_host = SSHKit::Host.new(&#34;#{MY.deploy_user}@#{MY.machine}&#34;)
  MY.deploy_to   = &#39;deploy_folder&#39;
  MY.remote_path = &#34;/var/rails/#{MY.deploy_to}&#34;
  MY.git_repo    = &#39;git@github.com:user/repo.git&#39;
  MY.git_branch  = &#39;branch&#39;
&lt;/pre&gt;

&lt;p&gt;With this code in place I will be able to call configuration in other files simply by calling:&lt;/p&gt;

&lt;pre class=&#34;brush: ruby; title: ; notranslate&#34; title=&#34;&#34;&gt;MY.deploy_user
&lt;/pre&gt;

&lt;p&gt;Now here is my bare &lt;code&gt;deploy.rake&lt;/code&gt; file with the three actions and comments to explain what&amp;#8217;s going on:&lt;/p&gt;

&lt;pre class=&#34;brush: ruby; title: ; notranslate&#34; title=&#34;&#34;&gt;namespace :deploy do
  desc &#34;Easy Peasy Setup&#34;
  task :setup do 
    # Setup directory and permissions on remote host
    on MY.deploy_host do |host|
      unless test &#34;[ -d #{MY.remote_path} ]&#34;
        within &#34;/var/rails&#34; do
          execute :git, :clone, MY.git_repo 
          execute :bundle, :install
          execute :rake, &#39;db:migrate&#39;
          execute :rake, &#39;db:seed&#39;
          execute :rake, &#39;assets:precompile&#39;
        end
      end
    end
  end

  desc &#34;Easy Peasy Update&#34;
  task :update do
    on MY.deploy_host do |host|
      within MY.remote_path do
        execute :git, :fetch
        execute :git, :reset, &#34;--hard origin/#{MY.git_branch}&#34;
        execute :bundle, :install if test(&#34;git diff HEAD^ HEAD | grep Gemfile&#34;)
        execute :rake, &#39;db:migrate&#39; if test(&#34;git diff HEAD^ HEAD | grep database.yml&#34;) || test(&#34;git diff HEAD^ HEAD -- db/&#34;)
        execute :rake, &#39;assets:precompile&#39; if test(&#34;git diff HEAD^ HEAD -- assets/&#34;)
      end
    end
  end
  
  desc &#34;Easy Peasy Rollback&#34;
  task :rollback do 
    on MY.deploy_host do |host|
      within MY.remote_path do
        # Before gitting back I need to rollback the db
        execute :rake, &#39;db:rollback&#39; if test(&#34;git diff HEAD^ HEAD | grep database.yml&#34;) || test(&#34;git diff HEAD^ HEAD -- db/&#34;)
        # And store Gemfile and assets changes before gitting back
        gem_changes = test(&#34;git diff HEAD^ HEAD | grep Gemfile&#34;)
        assets_changes = test(&#34;git diff HEAD^ HEAD -- assets/&#34;)
        # I then git back
        execute :git, :reset, &#39;--hard HEAD^&#39; 
        # And eventually perform bundle install and assets precompile
        # if there were previous changes
        execute :bundle, :install if gem_changes
        execute :rake, &#39;assets:precompile&#39; if assets_changes
      end
    end
  end
end
&lt;/pre&gt;

&lt;p&gt;The next article will be about the Machine Preparation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multithreaded Rails App 4 REAL</title>
      <link>http://thinkingco.de/techblog/multithreaded-rails-app-4-real/</link>
      <pubDate>Tue, 29 Oct 2013 02:33:24 &#43;0000</pubDate>
      
      <guid>http://thinkingco.de/techblog/multithreaded-rails-app-4-real/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://rubini.us/2013/10/04/rubinius-2-0-released/&#34;&gt;Rubinius 2.0&lt;/a&gt; (actually 2.1.1) is out and with it rails apps can finally be fully multithreaded taking advantage of multicore processors and substantially reducing memory consumption (&lt;a href=&#34;http://miguelcamba.com/blog/2013/10/05/benchmarking-the-ruby-2-dot-1-and-rubinius-2-dot-0/&#34;&gt;benchmark of latest ruby implementations&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Im currently porting a Rails 2 app to Rails 4. It is a patients management app with also image management.&lt;/p&gt;

&lt;p&gt;Some doctors have up to 4000 patients.&lt;/p&gt;

&lt;p&gt;My aim is to publish an alpha version of the revamped app on my local home server to let the users actually try the changes and be able to change the final output. At the same time the alpha deployment stack will be the same as the production deployment stack that is to say:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Rubinius 2.x&lt;/li&gt;
&lt;li&gt;rvm&lt;/li&gt;
&lt;li&gt;Nginx&lt;/li&gt;
&lt;li&gt;Puma&lt;/li&gt;
&lt;li&gt;Capistrano&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Actually my home server hosts my wordpress website served by apache2 on a debian distribution.&lt;/p&gt;

&lt;p&gt;So here goes my project&amp;#8217;s shopping list:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Install Rubinius 2.1.1&lt;/li&gt;
&lt;li&gt;Install nginx and make it serve the rails puma app while still serving the apache2 installed sites&lt;/li&gt;
&lt;li&gt;Install puma and let it start as a daemon&lt;/li&gt;
&lt;li&gt;Configure Capistrano to deploy the alpha Rails 4 app to the selected stack&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;First thing first just get rvm and install it:&lt;/p&gt;

&lt;p&gt;As stated on &lt;a href=&#34;http://rubini.us/2013/09/22/ready-set/&#34; target=&#34;_blank&#34;&gt;rubinius blog&lt;/a&gt; to build rubinius 2 you either need rubinius master or ruby MRI 2. But luckily rvm automatically installs the MRI 2 for you so &amp;#8220;all you need is &lt;a href=&#34;http://rvm.io&#34; target=&#34;_blank&#34;&gt;love!&amp;#8221; for rvm which needs some money for its version 2&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;This will install MRI 2 and rubinius 2.1.1 (at writing time).&lt;/p&gt;

&lt;p&gt;So now that we have rubinius installed let&amp;#8217;s proceed with our world domination program and see how we can install nginx and configure it as a reverse proxy to serve this wordpress site running on apache 2 (if you can read this it&amp;#8217;s working …. phew)!&lt;/p&gt;

&lt;p&gt;Just one thing to note, you need to set the &lt;code&gt;client_max_body_size&lt;/code&gt; to use the automatic wordpress updates and installation of themes and plugins from zip files located on your device. Next we need to configure Apache 2 to listen on a different port than 80, I&amp;#8217;m using 8080. Change &lt;code&gt;/etc/apache2/ports.conf&lt;/code&gt;, &lt;code&gt;/etc/apache2/apache2.conf&lt;/code&gt; and every virtual host directive to listen and answer to port 8080:&lt;/p&gt;

&lt;p&gt;Restarting Apache and reloading nginx will bring online the new web server asset serving rails apps through nginx and php apps through apache2.&lt;/p&gt;

&lt;p&gt;Next we need to install puma and configure nginx to serve puma applications. As I&amp;#8217;m deploying a rails 4 app installing puma means adding a gem to my &lt;code&gt;Gemfile&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;and then doing a &lt;code&gt;bundle install&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Next we configure nginx to serve a puma app listening on a unix socket. We add a site to &lt;code&gt;/etc/nginx/sites-available/&lt;/code&gt; and paste this configuration inside it:&lt;/p&gt;

&lt;p&gt;The paths in the configuration are based on my Capistrano &lt;code&gt;deploy.rb&lt;/code&gt; which we&amp;#8217;ll see in a minute. It&amp;#8217;s a git based capistrano recipe using a &lt;code&gt;web&lt;/code&gt; prefix folder.&lt;/p&gt;

&lt;p&gt;Next we need to configure puma and capistrano in our app modifying &lt;code&gt;config/puma.rb&lt;/code&gt; and &lt;code&gt;config/deploy.rb&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;See the &lt;a href=&#34;https://github.com/puma/puma/blob/master/examples/config.rb&#34; target=&#34;_blank&#34;&gt;puma.rb example file&lt;/a&gt; to get you started, here is my puma configuration:&lt;/p&gt;

&lt;p&gt;The puma init.d script which will take care of starting and stopping puma daemons for every rails app is:&lt;/p&gt;

&lt;p&gt;And now the core of every Rails deployment &amp;#8230; the &lt;code&gt;deploy.rb&lt;/code&gt; file in all its glory.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;DO YOU REALLY WANT A 500 LINES DEPLOY SCRIPT BACKED BY A FULL GEM?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I&amp;#8217;m tired of handling resources, shared, current and all the rvm, bundler tricks without knowing exactly what I&amp;#8217;m doing so please see my &lt;a href=&#34;http://thinkingco.de/2013/uncategorized/easy-peasy-deploy&#34;&gt;next post for an easy peasy deploy solution in Rails&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tailing problems in Windows</title>
      <link>http://thinkingco.de/techblog/tailing-problems-in-windows/</link>
      <pubDate>Sun, 17 Feb 2013 02:33:24 &#43;0000</pubDate>
      
      <guid>http://thinkingco.de/techblog/tailing-problems-in-windows/</guid>
      <description>&lt;p&gt;I built this beautiful dashboard collecting data from different sensors on a high efficiency vehicle.&lt;/p&gt;

&lt;p&gt;I opted for an html page with server-events.&lt;/p&gt;

&lt;p&gt;Now I need to tail two files every 0.2 seconds and those files are uptaded every 0.2 seconds. These in Windows 7 brings up random errors when tail.exe tries to read a file that&amp;#8217;s being updated in the same exact instant.&lt;/p&gt;

&lt;p&gt;This means that &lt;strong&gt;tail.exe uses file reading with an exclusive lock&lt;/strong&gt; &amp;#8230;. very baaaad!&lt;/p&gt;

&lt;p&gt;I wondered if powershell had a non locking mechanism for reading content from files.&lt;/p&gt;

&lt;p&gt;I whipped up something with Set-Content and Get-Content but to no avail because Get-Content seems to use a reading exclusive lock too!&lt;/p&gt;

&lt;p&gt;So I invoked the powers of ruby flock (f-ile lock) to overcome this problem.&lt;/p&gt;

&lt;p&gt;Try this on windows:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;launch the writing.rb process&lt;/li&gt;
&lt;li&gt;launch as many reading.rb processes you want&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You will find no problems nor errors!&lt;/p&gt;

&lt;p&gt;For &lt;a href=&#34;http://www.ruby-doc.org/core-1.9.3/File.html#method-i-flock&#34;&gt;more info on ruby flock options&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Who&#39;s calling? (I mean ruby method)</title>
      <link>http://thinkingco.de/techblog/whos-calling-i-mean-ruby-method/</link>
      <pubDate>Wed, 03 Oct 2012 02:33:24 &#43;0000</pubDate>
      
      <guid>http://thinkingco.de/techblog/whos-calling-i-mean-ruby-method/</guid>
      <description>&lt;p&gt;I needed to know which method was calling another method in a ruby app.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m writing a legacy protocol parser and need to control that received packets from the serial port stream are matching with commands replies.&lt;/p&gt;

&lt;p&gt;So I have a set of methods performing some commands and constants which represent correct replies:&lt;/p&gt;

&lt;p&gt;I wanted to be able to have the following interface to parse reply packets so that I can adapt the correct answer on the basis of the sent command:&lt;/p&gt;

&lt;p&gt;So I had to find a way to dynamically call the reply packet constant.&lt;/p&gt;

&lt;p&gt;I already named the constants with the same name as the called command prepended by an &lt;strong&gt;R_&lt;/strong&gt; standing for reply.&lt;/p&gt;

&lt;p&gt;The main problem was how to find the &lt;strong&gt;calling_method&lt;/strong&gt;.&lt;br /&gt;
I found out that in the ruby Kernel there is a method called &lt;strong&gt;caller&lt;/strong&gt; which prints the calling chain in a ruby script.&lt;br /&gt;
The only task was then to parse the last method name from the chain:&lt;/p&gt;

&lt;p&gt;The parse_answer method ended up being coded like this:&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Start vSphere machine from OSX</title>
      <link>http://thinkingco.de/techblog/start-vsphere-machine-from-osx/</link>
      <pubDate>Tue, 11 Sep 2012 02:33:24 &#43;0000</pubDate>
      
      <guid>http://thinkingco.de/techblog/start-vsphere-machine-from-osx/</guid>
      <description>&lt;p&gt;So I have a vSphere 5.1 free Hypervisor installed on a HP Microserver.&lt;/p&gt;

&lt;p&gt;Very nice hardware, very nice piece of software, so far so good.&lt;/p&gt;

&lt;p&gt;Unfortunately I don&amp;#8217;t have a Windows machine in my house except for a Win 7 which is virtualized on the vSphere machine.&lt;/p&gt;

&lt;p&gt;I don&amp;#8217;t want to install a Windows virtual machine on my MacBook just to start my Win 7 machine on the vSphere center.&lt;/p&gt;

&lt;p&gt;The virtualized Win 7 machine is equipped with vSphere Client.&lt;/p&gt;

&lt;p&gt;I tried several methods:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Ruby RVC (Remote Vsphere Console)&lt;/li&gt;
&lt;li&gt;iPad vShpere application&lt;/li&gt;
&lt;li&gt;vSphere Web Client&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;None of these worked.&lt;/p&gt;

&lt;p&gt;Ruby RVC cannot be used to perform API write operations with the free HyperVisor, it can be used with the trial (60 days) version or any other paid version.&lt;/p&gt;

&lt;p&gt;Both the iPad vSphere app and the web client option need the web client API to be enabled.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;This can be done &amp;#8230;. you guess it &amp;#8230;.. only from a Windows machine!!!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;So I was left with one choice: ssh console.&lt;/p&gt;

&lt;p&gt;I enabled it directly in the vSphere terminal and then managed to start up my Win 7 machine with some console ninja secret commandssssss &amp;#8230;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>EventMachine &amp;#038; SerialPort</title>
      <link>http://thinkingco.de/techblog/eventmachine-serialport/</link>
      <pubDate>Thu, 06 Sep 2012 02:33:24 &#43;0000</pubDate>
      
      <guid>http://thinkingco.de/techblog/eventmachine-serialport/</guid>
      <description>&lt;p&gt;I need to communicate with an inertial platform to track GPS data in a dashboard.&lt;/p&gt;

&lt;p&gt;As the dashboard is working with EventMachine I decided to use &lt;a href=&#34;https://github.com/hparra/ruby-serialport&#34;&gt;ruby-serialport&lt;/a&gt; with EventMachine.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;UPDATE&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;em-serialport is &lt;strong&gt;not working on Windows&lt;/strong&gt; furthermore, having a good chat on the irc eventmachine channel, the use of eventmachine pure ruby library is not at all efficient.&lt;/p&gt;

&lt;p&gt;First of all you can now install eventmachine version 1.0.0 on Windows.&lt;/p&gt;

&lt;p&gt;Then I decided to follow the approach used in &lt;a href=&#34;https://github.com/shokai/serialport-server/blob/master/bin/serialport-server&#34;&gt;serialport-server&lt;/a&gt; to listen to my serialport.&lt;/p&gt;

&lt;p&gt;The idea is simple: wrap the serial port connection in a websocket&amp;#8217;s one.&lt;/p&gt;

&lt;p&gt;Now in the main eventmachine reactor I can open a TCP server websocket connection to my Serial Port like this:&lt;/p&gt;

&lt;p&gt;It is working very well both on Windows and on OSX.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;THIS IS USELESS PLEASE DON&amp;#8217;T USE IT&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strike&gt;I found out there is a nice &lt;a href=&#34;https://github.com/railsbob/em-serialport&#34;&gt;em-serialport&lt;/a&gt; gem than can do the job.&lt;/p&gt;

&lt;p&gt;Unfortunately my dashboard will run on a Windows 7 pc.&lt;/p&gt;

&lt;p&gt;So here comes the first problem: the actual version of EventMachine (0.12.10) will not compile on windows.&lt;/p&gt;

&lt;p&gt;It is a well known issue and you simply will not be able to install it (nor any 0.12 version for what it matters).&lt;/p&gt;

&lt;p&gt;There is a solution though and it is to install the version 1.0.0.rc&lt;/p&gt;

&lt;p&gt;EventMachine will compile flawlessly and you will once more be a happy programmer.&lt;/p&gt;

&lt;p&gt;Unfortunately your happiness will not last because em-serialport requires in its gemspec eventmachine 0.12.10.&lt;/p&gt;

&lt;p&gt;So when you install em-serialport on windows it will complain that it cannot install EventMachine.&lt;/p&gt;

&lt;p&gt;If you force the gem installation with the &amp;#8211;no-dependencies flag it will install but when you require it it will happily blow up.&lt;/p&gt;

&lt;p&gt;So you need to change the gemspec file setting the pre version of EventMachine.&lt;/p&gt;

&lt;p&gt;Then you need to make another change in em-serialport.rb&lt;/p&gt;

&lt;p&gt;They improved the way pure_ruby EventMachine ruby can be loaded and you have to modify it like this:&lt;/p&gt;

&lt;p&gt;In the end just build the new gem from the gemspec and install it.&lt;/strike&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Rails 3 is_documentable with activeadmin</title>
      <link>http://thinkingco.de/techblog/rails-3-is_documentable-with-activeadmin/</link>
      <pubDate>Wed, 11 Jul 2012 02:33:24 &#43;0000</pubDate>
      
      <guid>http://thinkingco.de/techblog/rails-3-is_documentable-with-activeadmin/</guid>
      <description>&lt;p&gt;I need to add the chance to add as many documents as needed for several models of a Rails 3 app.&lt;/p&gt;

&lt;p&gt;Each model is something that can have associated drawings, administrative acts and so forth.&lt;/p&gt;

&lt;p&gt;To avoid duplication as far as possible I opted for an acts_as like feature for documents.&lt;/p&gt;

&lt;p&gt;It will be called acts as documentable.&lt;/p&gt;

&lt;p&gt;The acts as coding pattern rely on the &lt;a href=&#34;http://guides.rubyonrails.org/association_basics.html#polymorphic-associations&#34;&gt;polymorphic association&lt;/a&gt; with which a model can belong to more than one other model, on a single association.&lt;/p&gt;

&lt;p&gt;Let&amp;#8217;s see what this means.&lt;/p&gt;

&lt;p&gt;Let&amp;#8217;s imagine we have three models: User, Project and Tasks.&lt;/p&gt;

&lt;p&gt;We want each model to be able to store n documents uploaded by a user.&lt;/p&gt;

&lt;p&gt;With a polymorphic association we can obtain this result with the following Rails code:&lt;/p&gt;

&lt;p&gt;The polymorphic reference in the migration automatically creates two columns:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;documentable_id&lt;/strong&gt;: the id of the object to which the document will be added&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;documentable_type&lt;/strong&gt;: the class name of the object to which the document will be added&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this way Rails will be able to add n documents to each model which will be documentable.&lt;/p&gt;

&lt;p&gt;We thus need a way to extend each model with the Documentable module.&lt;/p&gt;

&lt;p&gt;This is achieved extending ActiveRecord::Base and is the &lt;strong&gt;&amp;#8220;standard&amp;#8221;&lt;/strong&gt; way of structuring a gem extension for ActiveRecord.&lt;/p&gt;

&lt;p&gt;Here is the structure:&lt;/p&gt;

&lt;p&gt;The documentable.rb file should be saved in the &lt;strong&gt;lib&lt;/strong&gt; folder.&lt;/p&gt;

&lt;p&gt;In Rails 3 because of the assets pipeline files included in the lib folder are no longer loaded by default.&lt;/p&gt;

&lt;p&gt;You both need to explicitly load files in the lib AND require them! I know it sounds strange but it&amp;#8217;s the only way I managed to extend ActiveRecord with my Documentable module.&lt;/p&gt;

&lt;p&gt;Now I can extend my models with the is_documentable class method and let them be able to have many documents:&lt;/p&gt;

&lt;p&gt;Now let&amp;#8217;s throw in a couple more things:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;dragonfly&lt;/strong&gt; to upload files&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;activeadmin&lt;/strong&gt; to manage documents&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For dragonfly nothing interesting, just follow the &lt;a href=&#34;http://markevans.github.com/dragonfly/file.README.html&#34;&gt;rails 3 quick start guide&lt;/a&gt; and use the &lt;strong&gt;file_accessor&lt;/strong&gt; instead of the image_accessor.&lt;/p&gt;

&lt;p&gt;Something more interesting for activeadmin. Here you can add a nested form for your documents using the wonderful &lt;strong&gt;has_many&lt;/strong&gt; form method:&lt;/p&gt;

&lt;p&gt;What this code does is simply to add a nested form for documents with buttons to add and remove each document!&lt;/p&gt;

&lt;p&gt;If you want some more info on the has_many method &lt;a href=&#34;https://github.com/gregbell/active_admin/issues/59&#34;&gt;check this page on active_admin&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Maybe I&amp;#8217;ll set up a gem &amp;#8230;. sometime &amp;#8230;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>RealTime dashboard: ruby, eventmachine and d3.js</title>
      <link>http://thinkingco.de/techblog/realtime-dashboard-ruby-eventmachine-and-d3-js/</link>
      <pubDate>Sat, 30 Jun 2012 02:33:24 &#43;0000</pubDate>
      
      <guid>http://thinkingco.de/techblog/realtime-dashboard-ruby-eventmachine-and-d3-js/</guid>
      <description>&lt;p&gt;We need to build a dashboard for a field veichle through which we collect different street data.&lt;/p&gt;

&lt;p&gt;We have two lasers used to monitor the status of pavimentation and three accelerometers to monitor that data acquisition be consistent and without spikes.&lt;/p&gt;

&lt;p&gt;We have a GPS to georeference all the collected data and a video camera to actually see the road and be able to log the presence of different kind of elements on the road graph.&lt;/p&gt;

&lt;p&gt;Finally we have an odometer to get actual vehicle speed.&lt;/p&gt;

&lt;p&gt;All these data are collected each 200ms.&lt;/p&gt;

&lt;p&gt;Data are collected in different ways:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;lasers and accelerometers values are written on a delimited txt file&lt;/li&gt;
&lt;li&gt;gps data are collected directly with its sdk through USB&lt;/li&gt;
&lt;li&gt;the camera takes 10 pictures/s which are written in a folder&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;I will focus here on lasers and accelerometers values which are all saved in a semicolon delimited file.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Data are collected through file modification/creation and this is the reason behind my first architectural choice:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;let the filesystem trigger change events in the dashboard&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is the fastest way to react to data changes since nothing can be more responsive than the filesystem itself to changes happening in its domain.&lt;/p&gt;

&lt;p&gt;Since I use ruby I can easily hook into filesystem events with these libraries:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;for OSX rb-fsevents&lt;/li&gt;
&lt;li&gt;for Linux rb-inotify&lt;/li&gt;
&lt;li&gt;for Windows win32-changenotify&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Then I needed a way to communicate real time with my web frontend.&lt;br /&gt;
I opted for eventmachine (because it&amp;#8217;s ruby!) and web sockets.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;UPDATE&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;eventmachine-tail&lt;/strong&gt; is not working on Windows because it leverages the eventmachine FileWatch class which actually is not compatible with Windows.&lt;/p&gt;

&lt;p&gt;Furthermore &lt;strong&gt;win32-changenotify&lt;/strong&gt; is not the good choice for NTFS systems, you should use &lt;strong&gt;win32-changejournal&lt;/strong&gt; which is not installing on my Windows 7 machine &lt;a href=&#34;https://github.com/djberg96/win32-changejournal/issues/3&#34;&gt;see issue here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So I changed approach and am now using &lt;a href=&#34;https://github.com/jordansissel/ruby-filewatch&#34;&gt;ruby-filewatch&lt;/a&gt; to tail my windows file (and OSX/Linux/Solaris) instead of eventmachine-tail.&lt;/p&gt;

&lt;p&gt;&lt;strike&gt;This brought about the natural choice of &lt;a href=&#34;https://github.com/jordansissel/eventmachine-tail&#34;&gt;eventmachine-tail&lt;/a&gt; for file tailing.&lt;/strike&gt;&lt;/p&gt;

&lt;p&gt;For the websocket there is &lt;a href=&#34;https://github.com/igrigorik/em-websocket&#34;&gt;em-websocket&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So here is the bare minimum for my websocket tail server:&lt;/p&gt;

&lt;p&gt;The core server creates a channel (embryonic em pub sub) and a web socket server on port 8080.&lt;/p&gt;

&lt;p&gt;Every connection to the web socket subscribes to the channel which is a dual synchronous communication way between server and all connected clients all in few lines of code.&lt;/p&gt;

&lt;p&gt;Now that the server is working let&amp;#8217;s think about the client.&lt;/p&gt;

&lt;p&gt;The client here will be a browser connecting to the web socket server through javascript.&lt;/p&gt;

&lt;p&gt;But you know javascript is so unrubyish I opted for a coffeescript object to manage the websocket connections. Here it is:&lt;/p&gt;

&lt;p&gt;As you might have noticed we need jQuery.&lt;/p&gt;

&lt;p&gt;So to put everything together you need to:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Start the eventmachine ruby server&lt;/li&gt;
&lt;li&gt;Start a webpage which includes the WSConnector class&lt;/li&gt;
&lt;li&gt;Start adding semicolon delimited data to the tailed file&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Point two needs further elaboration because you need to setup a simple rack application to compile coffescript and eventually scss and bundle all js and css into two files.&lt;/p&gt;

&lt;p&gt;I&amp;#8217;ll deal about this aspect in another post.&lt;/p&gt;

&lt;p&gt;The final bare html page will be something along these lines:&lt;/p&gt;

&lt;p&gt;As you can see I&amp;#8217;m using &lt;a href=&#34;http://code.shutterstock.com/rickshaw/&#34;&gt;Rickshaw&lt;/a&gt; which is a tool built on d3.js especially crafted for interactive time series line graphs.&lt;/p&gt;

&lt;p&gt;In tv var I specify the time interval which for my project is 200 milliseconds. I then instantiate an svg (d3.js) area of 600&amp;#215;200 pixels.&lt;/p&gt;

&lt;p&gt;Another interesting thing is the &lt;strong&gt;maxDataPoints&lt;/strong&gt; option which tells to Rickshaw to keep a maximum of 100 values at a time.&lt;/p&gt;

&lt;p&gt;The two data_values I&amp;#8217;m pushing into Rickshaw are the ones you can find in the &lt;strong&gt;WSConnector onmessage&lt;/strong&gt; method.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>My Website stack: WNWS</title>
      <link>http://thinkingco.de/techblog/my-website-stack-wnws/</link>
      <pubDate>Fri, 08 Jun 2012 02:33:24 &#43;0000</pubDate>
      
      <guid>http://thinkingco.de/techblog/my-website-stack-wnws/</guid>
      <description>&lt;p&gt;After much thinking and wondering around through many solutions I opted for the following stack:&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;W&lt;/strong&gt;ebbynode&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;N&lt;/strong&gt;ginx&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;W&lt;/strong&gt;ordpress&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;S&lt;/strong&gt;vbtle&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;I already had a Webbynode account and this was an easy choice.&lt;br /&gt;
My Webby is actually configured with nginx which is also my default webserver for rails deployments: another easy choice.&lt;/p&gt;

&lt;p&gt;I fell in love with &lt;a href=&#34;http://svbtle.com/&#34;&gt;svbtle&lt;/a&gt; layout and administrative interface because I find it very clean and relaxing like the IA Writer I use in my iPad. But svbtle is a closed bunch of geniuses and I&amp;#8217;m not that kind of boy, so I began searching for a solution.&lt;/p&gt;

&lt;p&gt;There is &lt;a href=&#34;https://github.com/NateW/obtvse&#34;&gt;obtvse&lt;/a&gt; a svbtle rails clone but I preferred a solid and rich blogging platform as WordPress for which I already bought some components which will help me quickly setup landing pages and the likes.&lt;/p&gt;

&lt;p&gt;So I ended up with &lt;a href=&#34;https://github.com/gravityonmars/wp-svbtle&#34;&gt;wp-svbtle&lt;/a&gt; which is an open source template for WordPress.&lt;/p&gt;

&lt;p&gt;An so ended the quest of choosing the building blocks.&lt;/p&gt;

&lt;p&gt;To deploy an application with RAPP (Rapid Apps) I use the &lt;a href=&#34;https://github.com/webbynode/webbynode&#34;&gt;webbynode ruby gem&lt;/a&gt; which needs to be a git repo.&lt;/p&gt;

&lt;p&gt;So I forked the WordPress git repository on my account and cloned it locally I then initiated the webbynode rapp with a PHP engine and pushed it on my webby and use the &lt;a href=&#34;http://guides.webbynode.com/articles/rapidapps/dns.html&#34;&gt;change_dns&lt;/a&gt; command to point it to my &lt;strong&gt;thinkingco.de&lt;/strong&gt; domain.&lt;/p&gt;

&lt;p&gt;The init and push commands take also care of setting up a mysql database and password with the name of your app. But I found myself in need to setup the password for the user and grant him access to the database:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ mysql -u root -pmy-root-mysql-password

mysql&amp;gt; grant all on app_db_name.* to &#39;app_user_name&#39;@localhost identified by &#39;app_user_mysql_password&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then I pointed my browser to thinkingco.de and inserted the configuration data in the wordpress &lt;a href=&#34;http://codex.wordpress.org/File:install-step3.png&#34;&gt;wp-config.php&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Now I wanted a way to easily install plugins and update wordpress itself so I needed to install the &lt;strong&gt;php ssh library&lt;/strong&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo apt-get install libssh2-php
$ sudo /etc/init.d/nginx restart
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then I updated the &lt;strong&gt;wp-config.php&lt;/strong&gt; file adding the following lines:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;define(&#39;FS_METHOD&#39;, &#39;direct&#39;); // &#39;ssh&#39; is also an option, but did not work for my setup
define(&#39;FTP_BASE&#39;, &#39;/opt/local/nginx/html/domain.com/&#39;);
define(&#39;FTP_CONTENT_DIR&#39;, &#39;/opt/local/nginx/html/domain.com/wp- content/&#39;);
define(&#39;FTP_PLUGIN_DIR &#39;, &#39;/opt/local/nginx/html/domain.com/wp-content/plugins/&#39;);
define(&#39;FTP_PUBKEY&#39;, &#39;/home/username/.ssh/id_rsa.pub&#39;);
define(&#39;FTP_PRIKEY&#39;, &#39;/home/username/.ssh/id_rsa&#39;);
define(&#39;FTP_USER&#39;, &#39;username&#39;);
define(&#39;FTP_HOST&#39;, &#39;your-domain.com:22&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now my wordpress site was able to install plugins/themes or update itself. You could need to update permissions for wordpress files:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ chown -R www-data /your/wordpress/app
$ chmod g+x /your/wordpress/app
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After installing each single plugin I ssh into my webby and from there push back to my github forked repo this keeping my fork updated.&lt;/p&gt;

&lt;p&gt;One last thing is to be able to use pretty urls without using rewrite rules in nginx this can be achieved with the &lt;strong&gt;try_files&lt;/strong&gt; code line:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;location / {
          root   /your/app/root;
          index  index.php index.html index.htm;
          try_files $uri $uri/ /index.php;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So now you know how this website is built, all the process was quite straightforward and I&amp;#8217;m happy with the result.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Thinking Code</title>
      <link>http://thinkingco.de/techblog/thinking-code/</link>
      <pubDate>Wed, 06 Jun 2012 02:33:24 &#43;0000</pubDate>
      
      <guid>http://thinkingco.de/techblog/thinking-code/</guid>
      <description>&lt;p&gt;I thought that, almost in my forties, I was big enough to have my own website.&lt;br /&gt;
The name thinking code is obviously linked to my job as a developer which is mainly thinking about code.&lt;/p&gt;

&lt;p&gt;But this won&amp;#8217;t be only a blog about ruby and rails code, I&amp;#8217;d like to talk about different codes. There are several codes you can find in society:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;economical&lt;/li&gt;
&lt;li&gt;political&lt;/li&gt;
&lt;li&gt;ethical&lt;/li&gt;
&lt;li&gt;anthropological&lt;/li&gt;
&lt;li&gt;theological&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I like to write about all this different topics trying to unveil patterns, errors and possible refactoring.&lt;br /&gt;
Sometimes looking at things from other perspectives is stimulating and can bring about new ideas and solutions.&lt;br /&gt;
What about a Test Driven Development theory for economy or a Behavior Driven Development of a political system.&lt;/p&gt;

&lt;p&gt;Actually both the economical and the political systems are out of control and is quite self evident that the last great ideology of the west is crumbling down.&lt;/p&gt;

&lt;p&gt;There has never been a better moment to debug errors in the existing codes and think about new solutions.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>